import time
import os
import requests
import json

# PARAMETERS
CHUNK_SIZE = 20_000  # 20.000 số lượng document tối đa trong 1 file json
# SAVE_COLLECTION_FOLDER = "/home/sontv17/cyberbot/k8s-nth-guideline/tla-deployment-guideline/database/2. solr_init_code"  # thư mục lưu trữ file json
SAVE_COLLECTION_FOLDER = "/home/sontv17/cyberbot/k8s-nth-guideline/tla-deployment-guideline/database/2. solr_init_code/solr_data"  # thư mục lưu trữ file json
PRODUCT_URL_TEMPLATE = "http://solrcc.toaan.gov.vn/solr/{}/select?q=*%3A*"

COLLECTIONS = ["GroupTemplates",
                "Precedent",
                "Forms",
                "Law",
                "LawDetail",
                "Handbook",
                "tlacc_faq_test",
                "Verdict",
                "Tutorial",
                "test",
                "Terms",
                "document_detail",
                "document_shell",
                "GroupRelates",
                "tlacc_faq",
                "ExternalApiFails",
                "document_content",
                "TLACCTermsV2",
                "LawDetailMap",
                "BackupNoteChild",
                "Rates",
                "ContributeFaq",
                "document",
                "document_diagrams",
                "WordRecommend",
                "Case",
                "Field",
                "legal_instructions",
                "BackupNote",
                "News",
                "TLACCTerms",
                "Faq",
                "LawElements"]

COLLECTIONS = ["tlacc_faq"]

def get_collection(collection_url, save_file, start, rows):
    url = "{}&rows={}&start={}&sort=id%20asc".format(collection_url, rows, start)
    
    s_time = time.time()
    response = requests.get(url)
    response = json.loads(response.text)
    print("time: ", time.time() - s_time)
    
    docs = response['response']['docs']
    print("Queried {} documents for collection=[{}] start=[{}] rows=[{}]".format(len(docs), collection, start, rows))
    
    new_docs = []
    for doc in docs:
        doc.pop('_version_')
        new_docs.append(doc)
    print("Removed _version_ field")
    
    with open(save_file, "w") as f:
        json.dump(new_docs, f, ensure_ascii=False, indent=2)
    print("Saved collection [{}] to: {}".format(collection, save_file))


if __name__ == '__main__':
    
    for collection in COLLECTIONS:
        
        collection_url = PRODUCT_URL_TEMPLATE.format(collection)
        
        print("url: {}".format(collection_url))
        
        response = requests.get(collection_url)
        response = json.loads(response.text)
        
        total_docs = response['response']['numFound']
        
        if total_docs < CHUNK_SIZE:
            save_file = os.path.join(SAVE_COLLECTION_FOLDER, collection + ".json")
            get_collection(collection_url, save_file, 0, total_docs)
        else:
            start = 0
            end = CHUNK_SIZE
            chunk_files = []
            
            # EXPORT CHUNK DATA
            while end <= total_docs and start != end:
                save_file = os.path.join(SAVE_COLLECTION_FOLDER, "{}_{}_{}.json".format(collection, start + 1, end))
                
                get_collection(collection_url, save_file, start, CHUNK_SIZE)
                
                chunk_files.append(save_file)
                start = end
                end = total_docs if (end + CHUNK_SIZE) > total_docs else (end + CHUNK_SIZE)
            
        print("-" * 150)
